# Decision Flow

> Human-Like Decision Making with Intuitive Priors

This document describes how the Intuition Engine shapes decision-making, combining fast intuitive hits with deliberate reasoning in a flow that mirrors expert human cognition.

```mermaid
flowchart TB
    subgraph REQUEST["ðŸ“‹ Decision Request"]
        Q["Should we launch this token<br/>with quadratic governance?"]
    end

    subgraph PHASE1["âš¡ Phase 1: Immediate Intuition (~1-5ms)"]
        direction LR
        P1A["Embed Context"] --> P1B["Retrieve Lessons"]
        P1B --> P1C["Apply Soft Biases"]
        P1C --> P1D["'Gut Feeling' Priors"]
    end

    subgraph PHASE2["ðŸ¤” Phase 2: Deliberate Reasoning (~100ms-10s)"]
        direction LR
        P2A["Chain-of-Thought<br/>Analysis"] --> P2B["Tool Use &<br/>Simulation"]
        P2B --> P2C["Planning &<br/>Evaluation"]
        P2C --> P2D["Reasoned<br/>Decision"]
    end

    subgraph PHASE3["ðŸ”„ Phase 3: Post-Decision Reflection (async)"]
        direction LR
        P3A["Evaluate<br/>Outcomes"] --> P3B["Extract<br/>Lessons"]
        P3B --> P3C["Reinforce/<br/>Decay"]
        P3C --> P3D["Update<br/>Memory"]
    end

    REQUEST --> PHASE1
    PHASE1 -->|"Intuitive biases shape reasoning"| PHASE2
    PHASE2 -->|"Decision made"| ACTION["âœ… Action Taken"]
    ACTION -->|"Outcome observed"| PHASE3
    PHASE3 -.->|"Improved intuition"| PHASE1

    style REQUEST fill:#1a1a2e,stroke:#e94560,color:#fff
    style PHASE1 fill:#3498db,stroke:#2980b9,color:#fff
    style PHASE2 fill:#9b59b6,stroke:#8e44ad,color:#fff
    style PHASE3 fill:#2ecc71,stroke:#27ae60,color:#fff
    style ACTION fill:#f39c12,stroke:#d68910,color:#fff
```

---

## The Three-Phase Decision Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DECISION REQUEST                            â”‚
â”‚                                                                 â”‚
â”‚  "Should we launch this token with quadratic governance?"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 1: IMMEDIATE INTUITION                       â”‚
â”‚                        (~1-5ms)                                 â”‚
â”‚                                                                 â”‚
â”‚  â€¢ Embed context                                                â”‚
â”‚  â€¢ Retrieve top lessons from fast layer                         â”‚
â”‚  â€¢ Apply soft biases to decision space                          â”‚
â”‚                                                                 â”‚
â”‚  Result: "Gut feeling" priors that shape attention              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 2: DELIBERATE REASONING                      â”‚
â”‚                       (~100ms - 10s)                            â”‚
â”‚                                                                 â”‚
â”‚  â€¢ Full chain-of-thought analysis                               â”‚
â”‚  â€¢ Tool use (search, compute, simulate)                         â”‚
â”‚  â€¢ Planning and evaluation                                      â”‚
â”‚  â€¢ Intuitive biases shape reasoning direction                   â”‚
â”‚                                                                 â”‚
â”‚  Result: Reasoned decision with supporting analysis             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 3: POST-DECISION REFLECTION                  â”‚
â”‚                       (async, ~1-60s)                           â”‚
â”‚                                                                 â”‚
â”‚  â€¢ Evaluate outcome against predictions                         â”‚
â”‚  â€¢ Extract new lessons                                          â”‚
â”‚  â€¢ Reinforce or decay applied lessons                           â”‚
â”‚  â€¢ Update memory systems                                        â”‚
â”‚                                                                 â”‚
â”‚  Result: Improved intuition for next decision                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 1: Immediate Intuition

The moment a decision is required, the system activates its intuitive layer.

### Process

```python
def immediate_intuition(decision_context: Context) -> IntuitiveFrame:
    """
    Generate instant intuitive biases for a decision context.
    Must complete in <5ms.
    """

    # Step 1: Embed the current situation
    context_embedding = fast_embed(decision_context)

    # Step 2: Retrieve relevant lessons
    intuitive_hits = intuition_memory.fast_retrieve(
        context_embedding,
        k=10,
        min_strength=0.3
    )

    # Step 3: Aggregate into biases
    biases = aggregate_biases(intuitive_hits)

    # Step 4: Create intuitive frame
    return IntuitiveFrame(
        attention_priors=biases.attention_shifts,
        action_biases=biases.action_adjustments,
        caution_signals=biases.warnings,
        confidence_adjustment=biases.confidence_modifier,
        source_lessons=intuitive_hits
    )
```

### Types of Intuitive Biases

| Bias Type | Effect | Example |
|-----------|--------|---------|
| **Attention Shift** | Focus on specific aspects | "Pay extra attention to sybil resistance" |
| **Action Preference** | Increase/decrease certain actions | "Prefer established patterns over novel ones" |
| **Caution Signal** | Flag potential risks | "Similar situations had security issues" |
| **Confidence Modifier** | Adjust certainty | "High uncertainty domain, be conservative" |
| **Speed Adjustment** | Slow down or speed up | "This is well-trodden territory, proceed" |

### Example Intuitive Hits

For the token launch decision:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    INTUITIVE HITS (5 of 10)                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                   â•‘
â•‘  1. [Strength: 0.87, Relevance: 0.92]                             â•‘
â•‘     "Token launches without community validation underperform"    â•‘
â•‘     â†’ Bias: INCREASE validation_steps                             â•‘
â•‘                                                                   â•‘
â•‘  2. [Strength: 0.78, Relevance: 0.85]                             â•‘
â•‘     "Quadratic voting needs sybil resistance"                     â•‘
â•‘     â†’ Bias: REQUIRE identity_verification                         â•‘
â•‘                                                                   â•‘
â•‘  3. [Strength: 0.72, Relevance: 0.81]                             â•‘
â•‘     "Complex governance on launch day confuses users"             â•‘
â•‘     â†’ Bias: PREFER simple_initial_governance                      â•‘
â•‘                                                                   â•‘
â•‘  4. [Strength: 0.94, Relevance: 0.67]                             â•‘
â•‘     "Rushing high-stakes decisions has 3x failure rate"           â•‘
â•‘     â†’ Bias: INCREASE deliberation_time                            â•‘
â•‘                                                                   â•‘
â•‘  5. [Strength: 0.65, Relevance: 0.88]                             â•‘
â•‘     "Successful launches had clear value proposition first"       â•‘
â•‘     â†’ Bias: REQUIRE value_prop_clarity_check                      â•‘
â•‘                                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Phase 2: Deliberate Reasoning

With intuitive priors set, the system engages in full analytical reasoning.

### How Intuition Shapes Reasoning

```python
def deliberate_reasoning(
    decision_context: Context,
    intuitive_frame: IntuitiveFrame
) -> Decision:
    """
    Full chain-of-thought reasoning with intuitive guidance.
    """

    # Initialize reasoning with intuitive priors
    reasoning_state = ReasoningState(
        attention_weights=intuitive_frame.attention_priors,
        action_priors=intuitive_frame.action_biases,
        confidence_baseline=intuitive_frame.confidence_adjustment
    )

    # Step 1: Problem decomposition (guided by attention priors)
    sub_problems = decompose_with_attention(
        decision_context,
        reasoning_state.attention_weights
    )

    # Step 2: Information gathering (shaped by intuition)
    for problem in sub_problems:
        # Intuition might say "dig deeper here"
        if reasoning_state.should_investigate_further(problem):
            gather_additional_info(problem)

    # Step 3: Option generation (with intuitive filtering)
    options = generate_options(decision_context)
    # Intuition pre-scores options
    scored_options = apply_intuitive_scores(options, intuitive_frame)

    # Step 4: Evaluation (with calibrated confidence)
    evaluated_options = []
    for option in scored_options:
        evaluation = evaluate_option(option)
        # Adjust confidence based on intuitive signals
        evaluation.confidence *= reasoning_state.confidence_baseline
        evaluated_options.append(evaluation)

    # Step 5: Decision with intuitive integration
    decision = select_best_option(
        evaluated_options,
        intuitive_frame.caution_signals
    )

    return decision
```

### Integration Mechanisms

#### 1. Logit Adjustment

Intuitive biases can directly adjust the probability distribution over actions:

```python
def apply_intuitive_logits(
    base_logits: Tensor,
    intuitive_frame: IntuitiveFrame
) -> Tensor:
    """
    Shift logits based on intuitive biases.
    """
    adjusted = base_logits.clone()

    for bias in intuitive_frame.action_biases:
        if bias.type == 'increase':
            adjusted[bias.target_action] += bias.magnitude * INTUITION_STRENGTH
        elif bias.type == 'decrease':
            adjusted[bias.target_action] -= bias.magnitude * INTUITION_STRENGTH
        elif bias.type == 'forbid':
            adjusted[bias.target_action] = -float('inf')

    return adjusted
```

#### 2. Attention Steering

Intuition guides where the model focuses:

```python
def steer_attention(
    query: Query,
    intuitive_frame: IntuitiveFrame
) -> Query:
    """
    Modify attention to emphasize intuition-flagged aspects.
    """
    for attention_prior in intuitive_frame.attention_priors:
        query.add_emphasis(
            aspect=attention_prior.focus_area,
            weight=attention_prior.importance
        )

    return query
```

#### 3. System Prompt Injection

Intuitive guidance can be surfaced as explicit prompts:

```python
def generate_intuitive_prompt(intuitive_frame: IntuitiveFrame) -> str:
    """
    Convert intuitive biases to natural language guidance.
    """
    lines = ["Based on past experience, consider:"]

    for hit in intuitive_frame.source_lessons[:5]:
        lines.append(f"- {hit.lesson_core}")

    if intuitive_frame.caution_signals:
        lines.append("\nCautions:")
        for caution in intuitive_frame.caution_signals:
            lines.append(f"- âš ï¸ {caution}")

    return "\n".join(lines)
```

---

## Phase 3: Post-Decision Reflection

After a decision is made and outcomes observed, the system learns.

### Reflection Process

```python
async def post_decision_reflection(
    decision_context: Context,
    decision: Decision,
    intuitive_frame: IntuitiveFrame,
    outcome: Outcome
):
    """
    Learn from decision outcome. Runs asynchronously.
    """

    # Step 1: Evaluate outcome
    success_score = evaluate_outcome(outcome, decision.expected_outcome)

    # Step 2: Attribute to lessons
    for hit in intuitive_frame.source_lessons:
        if hit_contributed_to_outcome(hit, decision, outcome):
            # Reinforce or weaken based on success
            await reinforce_lesson(
                lesson_id=hit.lesson_id,
                outcome_score=success_score,
                context=decision_context
            )

    # Step 3: Extract new lessons
    new_lessons = await extract_lessons_from_episode(
        Episode(
            context=decision_context,
            actions=[decision],
            outcomes=outcome,
            feedback=FeedbackSet(
                internal=generate_reflection(decision, outcome),
                external=outcome.external_feedback
            )
        )
    )

    # Step 4: Store new lessons
    for lesson in new_lessons:
        await intuition_memory.store(lesson)

    # Step 5: Update neural router
    await router.update(
        context=decision_context,
        retrieved_lessons=intuitive_frame.source_lessons,
        outcome=outcome
    )
```

### Reinforcement Dynamics

```
                 Outcome
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚
    Success                  Failure
        â”‚                       â”‚
        â–¼                       â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Strengthenâ”‚           â”‚  Weaken   â”‚
  â”‚ +0.05     â”‚           â”‚  -0.10    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚
        â–¼                       â–¼
  Lesson more              Lesson less
  likely to fire           likely to fire
  next time                or flagged for
                           review
```

---

## Worked Example

### Scenario

> "Should we launch the DeFi yield aggregator with the novel auto-rebalancing mechanism?"

### Phase 1: Immediate Intuition (~3ms)

```
Context embedded â†’ Fast retrieval initiated

Retrieved lessons:
1. "Novel financial mechanisms need extra security audits" (0.91)
2. "Yield products should start with capped TVL" (0.84)
3. "Auto-rebalancing can create MEV opportunities" (0.79)
4. "Community education reduces support burden" (0.72)
5. "Launch with fallback to manual if novel system fails" (0.68)

Intuitive Frame:
- ATTENTION: Security review, MEV mitigation, fallback systems
- BIAS: INCREASE audit_thoroughness, REQUIRE tvl_caps
- CAUTION: "Novel mechanism + yield = high-risk combination"
- CONFIDENCE: Reduce by 20% (novel territory)
```

### Phase 2: Deliberate Reasoning (~2s)

```
With intuitive guidance, the reasoning process:

1. SECURITY FOCUS (attention-guided)
   â†’ Commission additional MEV analysis
   â†’ Verify rebalancing logic edge cases
   â†’ Check for economic attack vectors

2. CONSERVATIVE APPROACH (bias-influenced)
   â†’ Design with TVL cap for launch
   â†’ Implement circuit breakers
   â†’ Create manual override system

3. CALIBRATED CONFIDENCE (intuition-adjusted)
   â†’ Recommend staged launch over full release
   â†’ Suggest longer beta period
   â†’ Prepare rollback procedures

Final Decision: Launch with modifications
- Add 72-hour security review
- Implement $1M TVL cap initially
- Build manual rebalancing fallback
- Stage launch over 3 phases
```

### Phase 3: Reflection (Post-Launch)

```
Outcome observed after 30 days:
- No security incidents âœ“
- TVL grew organically to cap âœ“
- Manual fallback used twice (minor bugs) âš ï¸
- Community reception positive âœ“

Lesson updates:
- "Staged launches for novel DeFi" reinforced (+0.05)
- "Manual fallbacks save launches" reinforced (+0.08)
- "TVL caps reduce risk" reinforced (+0.03)

New lesson extracted:
- "Auto-rebalancing edge cases appear at TVL > $500K"
```

---

## Decision Quality Metrics

### Real-Time Metrics

| Metric | Measurement |
|--------|-------------|
| Intuition Latency | Time to generate IntuitiveFrame |
| Reasoning Time | Total Phase 2 duration |
| Intuition Agreement | % of final decisions aligned with intuitive bias |
| Override Rate | % of decisions that explicitly overrode intuition |

### Outcome Metrics

| Metric | Measurement |
|--------|-------------|
| Intuition Accuracy | Success rate when following intuition |
| Override Accuracy | Success rate when overriding intuition |
| Calibration | Correlation between confidence and success |
| Learning Rate | Speed of lesson strength convergence |
